---
title: "Evaluations of positive and negative stimuli using the Affective Misattribution Procedure (AMP) and self-reports"
subtitle: "Data processing"
author: "Template: Ian Hussey; content: [Student name]"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r, include=FALSE}

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

```


# Dependencies

```{r}

library(tidyverse)
library(janitor) # for clean_names()
library(stringr)

```


#neuer versuch alle zeilen zu laden
```{r}
data_amp_raw <- read_csv("../data/raw/data_amp_raw.csv", n_max = 10000) |> 
  janitor::clean_names()
nrow(data_amp_raw)

```



# Get data

```{r}

# demographics
data_demographics_raw <- read_csv("../data/raw/data_demographics_raw.csv", n_max = 10000) |> 
  janitor::clean_names()

# Uncomment if you need this dataset
# data_demographics_raw_messy <- read_csv("../data/raw/data_demographics_raw.csv", skip = 2, n_max = 10000) |> 
#   janitor::clean_names()

# self report measure
data_selfreport_raw <- read_csv("../data/raw/data_selfreport_raw.csv", n_max = 10000) |> 
  janitor::clean_names()

# affect attribution procedure
data_amp_raw <- read_csv("../data/raw/data_amp_raw.csv", n_max = 10000) |> 
  janitor::clean_names()


```



#check ob die daten wirklich nur 200 zeilen haben oder obs die einfach nur so anzeigt: 
```{r}

nrow(data_demographics_raw)
nrow(data_selfreport_raw)
nrow(data_amp_raw)
```


# Demographics

```{r}

dat_age_gender <- data_demographics_raw |>
  select(subject, date, time, trialcode, response) |>
  pivot_wider(names_from = trialcode,
              values_from = response) |>
  mutate(gender = tolower(gender),
         gender = stringr::str_remove_all(gender, regex("\\W+")), # regex is both very useful and awful to write
         gender = case_when(gender == "female" ~ gender,
                            gender == "male" ~ gender,
                            gender == "nonbinary" ~ gender,
                            gender == "woman" ~ "female",
                            gender == "man" ~ "male",
                            TRUE ~ "other/missing/error"),
         age = case_when(str_detect(age, "^[0-9]+$") ~ age, # if the value is only numbers, keep it. 
                         TRUE ~ "other/missing/error")) 

```

# Exclusions / data quality

## AMP

```{r}

data_amp_performance_criteria <- data_amp_raw |> 
  filter(blockcode != "practice", 
         trialcode != "instructions") |> 
  mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |> 
  group_by(subject) |> 
  summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
  mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))

```

# Self-reports

```{r}

# trial level data
data_selfreport_trial_level <- data_selfreport_raw |>
  select(subject, trialcode, response) |>
  filter(trialcode %in% c("like", "prefer", "positive")) |>
  rename(item = trialcode) |>
  filter(response != "Ctrl+'B'") |>
  mutate(response = as.numeric(response))

# mean scored
data_selfreport_mean_score <- data_selfreport_trial_level |>
  group_by(subject) |>
  summarize(mean_evaluation = mean(response, na.rm = TRUE))

# combined
data_selfreport_scored <- 
  full_join(data_selfreport_trial_level |>
              pivot_wider(names_from = "item",
                          values_from = "response"),
            data_selfreport_mean_score,
            by = "subject")

```

# Affect Misattribution Procedure

TODO extract evaluations on the AMP test blocks and convert to an overall bias score

```{r}


```

# Combine

```{r}

# combine all dfs created in the previous chunks
data_processed_temp <- dat_age_gender |>
  full_join(data_selfreport_scored, by = "subject") |> 
  full_join(data_amp_performance_criteria, by = "subject")

# flag all subjects with more than one row in the wide-format data. these should be excluded in the analysis.
# a more elaborate approach would be to track down the individual dupicate cases and determine which of the mulitiple cases should be retained. 
data_processed_duplicates <- data_processed_temp |>
  count(subject) |>
  mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) |>
  select(-n)

# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp |>
  full_join(data_processed_duplicates, by = "subject")

```

# Define master exclusions

```{r}

# create a master exclude_participant variable
data_processed <- data_processed_before_exclusions |>
  mutate(exclude_participant = case_when(tolower(age) == "test" ~ "exclude",
                                         tolower(gender) == "test" ~ "exclude",
                                         is.na(mean_evaluation) ~ "exclude",
                                         # in this case we will exclude participants with missing demographics data or outcomes measures data. 
                                         # Note that "list-wise exclusions" like this aren't always justified, as missingness often isn't at random. 
                                         # How to treat missing data is a  whole area of work in itself, which we wont cover here.
                                         is.na(age) ~ "exclude", 
                                         is.na(gender) ~ "exclude",
                                         exclude_amp_performance == "exclude" ~ "exclude",
                                         exclude_duplicate_data == "exclude" ~ "exclude", is.na(like) ~ "exclude",
                                         is.na(positive) ~ "exclude", 
                                         is.na(prefer) ~ "exclude",
                                         TRUE ~ "include"))

```
#write to disk neue Lösung weil andere nicht geht

```{r}
# Create the directory if it doesn't exist
dir.create("/Users/tobiasboschung/Documents/GitHub/dpm-assignments/week 7/implicit evaluations study/data/processed", showWarnings = FALSE, recursive = TRUE)

# Save the processed data to the specified directory
write_csv(data_processed, "/Users/tobiasboschung/Documents/GitHub/dpm-assignments/week 7/implicit evaluations study/data/processed/data_processed.csv")

```

# Write to disk

```{r}

# in case this dir doesn't exist, create it
dir.create("../data/processed/")

# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")

          
          
```



#Find out how many trials are the average based on the data_amp_raw file



```{r}
# Step 1: Identify the mean number of trials per subject for 'test' blockcode
amp_test_data <- subset(data_amp_raw, blockcode == "test")
trial_counts_per_subject <- table(amp_test_data$subject)

# Summary statistics for trial counts
summary(as.numeric(trial_counts_per_subject))

# Step 2: Add exclusion criteria based on the "correct" number of trials (e.g., 72)
correct_trial_count <- 72
amp_test_data$exclude_based_on_trial_count <- "include"

# Mark subjects for exclusion if their trial count doesn't match the correct_trial_count
subjects_to_exclude <- names(trial_counts_per_subject)[as.numeric(trial_counts_per_subject) != correct_trial_count]
amp_test_data$exclude_based_on_trial_count[amp_test_data$subject %in% subjects_to_exclude] <- "exclude"

# Save the updated data
write.csv(amp_test_data, "data_amp_raw_with_exclusions.csv")

```
#i want to summarise the number of subjects who would get excluded

```{r}
# Summarize the inclusion and exclusion status for each subject
inclusion_summary <- amp_test_data %>% 
  group_by(subject) %>% 
  summarise(exclude_status = max(exclude_based_on_trial_count))

# Count the number of subjects included and excluded
table(inclusion_summary$exclude_status)
```

# now i want to see the ids of the participants who´d get excluded
```{r}
# List the subject IDs that are marked for exclusion
excluded_subject_ids <- inclusion_summary %>% 
  filter(exclude_status == "exclude") %>% 
  select(subject)

print("Subjects to be excluded:")
print(excluded_subject_ids)

```




# Session info

```{r}

sessionInfo()

```


